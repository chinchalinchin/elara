Appendix
========

This section contains notes and ideas that do not serve to establish the main results of the work, but the author believes may nevertheless prove useful in extending the formal theory into other epistemological domains.

Palindromic Pairs
^^^^^^^^^^^^^^^^^

The only constraint on a Language is that it must consist of Words. This is guaranteed by the Extraction Axiom S.2. The only constraint on Words is that they must not contain the Delimiter. This is guaranteed by the Delimiter Axiom W.1. 

Since *σ-reduction* removes the Delimiter Character when it projects a Sentence onto the *σ-reduced* Alphabet, this process can viewed as the construction of another formal Language. In other words, given a Language and Corpus, the operation of *σ-reduction* implies the existence of a second Language which encodes the original Sentences. This second Language loses much of its semantic coherence with respect to its "*mother*" Corpus, but it nevertheless contains semantic information. 

This idea motives the definition of a *σ-Pairing Language*.

**Definition 3.1.3: σ-Pairing Language**

The σ-Pairing Language L:sub:`σ` of a Corpus C:sub:`L` is defined as the set of Words *α* that satisfy the following formula, 

    α ∈ L:sub:`σ` ↔ ∃ ζ ∈ C:sub:`L`: α = (Ζ ⋅ Σ:sub:`σ`)

This definition captures the idea that the σ-Pairing Language consists of all the Strings that can be generated by applying σ-reduction to the Sentences in the Corpus. It directly links the elements of L:sub:σ to the σ-reduced forms of the Sentences, ensuring that the Pairing Language is derived from the original Corpus.

(TODO)

**Theorem 3.1.7** α ∈ L:sub:`σ` ↔ [ ∃ ζ ∈ C:sub:`L`: ∃ (i, β) ∈ W:sub:`ζ`: β ⊂:sub:`s` α ]

This theorem can be stated in natural language as follows: The *σ*-Pairing Language contains a Word *α* if and only if there exists a Sentence *ζ* and a Word *β* that belongs to Sentence *ζ* such that *α* is contained in *Ζ ⋅ Σ*:sub:`σ`.

Theorem 3.1.7: α ∈ L:sub:σ ↔ [ ∃ ζ ∈ C:sub:L: ∃ (i, β) ∈ W:sub:ζ: β ⊂:sub:s α ]

Proof:

(→) Assume α ∈ L:sub:σ.

Definition of σ-Pairing Language: By Definition 3.1.3 (revised), ∃ ζ ∈ C:sub:L: α = (Ζ ⋅ Σ:sub:σ).

Word-level representation: Let W:sub:ζ = (β₁, β₂, ..., βₙ) be the Word-level representation of ζ.

σ-reduction: By the definition of σ-reduction, (Ζ ⋅ Σ:sub:σ) is obtained by concatenating the Words in W:sub:ζ without Delimiters:

α = (Ζ ⋅ Σ:sub:σ) = β₁β₂...βₙ

Containment: Since each βᵢ is a contiguous subsequence of α, it follows that ∀ i ∈ N:sub:n: βᵢ ⊂:sub:s α.

Therefore, ∃ ζ ∈ C:sub:L: ∃ (i, β) ∈ W:sub:ζ: β ⊂:sub:s α.

(←) Assume ∃ ζ ∈ C:sub:L: ∃ (i, β) ∈ W:sub:ζ: β ⊂:sub:s α.

Word-level representation: Let W:sub:ζ = (β₁, β₂, ..., βₙ) be the Word-level representation of ζ, and let βᵢ be the Word such that βᵢ ⊂:sub:s α.

σ-reduction: By the definition of σ-reduction, (Ζ ⋅ Σ:sub:σ) is obtained by concatenating the Words in W:sub:ζ without Delimiters:

(Ζ ⋅ Σ:sub:σ) = β₁β₂...βₙ

Containment and concatenation: Since βᵢ ⊂:sub:s α and α is a String formed by concatenating Words, it follows that α must be a contiguous subsequence of (Ζ ⋅ Σ:sub:σ).

Equality:  Since α is a contiguous subsequence of (Ζ ⋅ Σ:sub:σ) and both are Strings formed by concatenating the same Words in the same order (without Delimiters), it follows that α = (Ζ ⋅ Σ:sub:σ).

Therefore, α ∈ L:sub:σ by Definition 3.1.3 (revised).

Since we have proven both directions of the implication, the theorem is established:

α ∈ L:sub:σ ↔ [ ∃ ζ ∈ C:sub:L: ∃ (i, β) ∈ W:sub:ζ: β ⊂:sub:s α ] ∎

Explanation:

This theorem effectively characterizes the elements of the σ-Pairing Language. It states that a String belongs to the σ-Pairing Language if and only if it contains a Word from some Sentence in the Corpus. This highlights the connection between the σ-Pairing Language and the original Language and Corpus.

(TODO: Need to prove this!)

**Definition: Palindromic Pairing Language**

Definition 3.1.3 is altered in the following definition to quantify over the set of Palindromes in a Corpus. The Pairing Language that results is denoted L:sub:`P`. The set of Words *α* which satisfy this definition are referred to as the Palindromic Pairing Language of Language **L**, 

    α ∈ L:sub:`P` ↔  ∃ ζ ∈ P: α = (Ζ ⋅ Σ:sub:`σ`)

In particuar, if *α ∈ L*:sub:`P`, *α* is called the *Palindromic Image* of the Sentences *ζ* which generate it.

This definition is used to prove the following theorems.

**Theorem** L:sub:`P` ⊂ L:sub:`σ`

Assume α ∈ L:sub:P.  By Definition 3.1.4 (Palindromic Pairing Language), this means:

∃ ζ ∈ P: α = (Ζ ⋅ Σ:sub:σ)

Palindrome is a Sentence: By Definition 3.1.2 (Palindromes), P (the set of Palindromes) is a subset of C:sub:L (the Corpus). Therefore, ζ ∈ C:sub:L.

σ-Pairing Language: Since ζ ∈ C:sub:L and α = (Ζ ⋅ Σ:sub:σ), by Definition 3.1.3 (σ-Pairing Language), it follows that α ∈ L:sub:σ.

Therefore, if α ∈ L:sub:P, then α ∈ L:sub:σ. This implies L:sub:P ⊂ L:sub:σ. ∎

Explanation:

This proof demonstrates that the Palindromic Pairing Language (L:sub:P) is a subset of the σ-Pairing Language (L:sub:σ). This is because every String in the Palindromic Pairing Language is derived from a Palindrome, which is also a Sentence in the Corpus, and therefore its σ-reduction belongs to the σ-Pairing Language.

This result is intuitive, as the Palindromic Pairing Language is essentially a specialized version of the σ-Pairing Language, focusing specifically on the σ-reductions of Palindromes.

(TODO: Need to prove this)

**Theorem**: ∀ α ∈ L:sub:`P`: α = inv(α)

This theorem can be stated in natural language as follows: All Words in a Palindromic Pairing Language are their own Inverses. 

Assume α ∈ L:sub:P. By Definition 3.1.4 (Palindromic Pairing Language), this means:

∃ ζ ∈ P: α = (Ζ ⋅ Σ:sub:σ)

Palindrome Definition: Since ζ ∈ P (ζ is a Palindrome), by Definition 3.1.2:

(Ζ ⋅ Σ:sub:σ) = inv(Ζ ⋅ Σ:sub:σ)

Substitution: Substituting α from step 1 into the equation in step 2, we get:

α = inv(α)

Therefore, ∀ α ∈ L:sub:P: α = inv(α). ∎

Explanation:

This proof demonstrates that every String in the Palindromic Pairing Language is its own inverse. This follows directly from the definitions of Palindromes and the Palindromic Pairing Language. Since every String in the Palindromic Pairing Language is derived from a Palindrome, and Palindromes are defined by the invariance of their σ-reduction under inversion, the Strings in the Palindromic Pairing Language must also exhibit this invariance.

This theorem highlights a key property of the Palindromic Pairing Language: it consists solely of Strings that are symmetrical with respect to inversion. This property could be useful in various applications, such as identifying potential palindromes or generating text with specific symmetrical structures.


**Theorem** L ∩ L:sub:`P` ⊆ R

This theorem can be stated in natural language as follows: The intersection of a Language **L** and its Palindromic Pair **L**:sub:`P` is a subset of the Language's Reflective Words **R**.


Statement: This theorem accurately states that the intersection of the Language (L) and its Palindromic Pairing Language (L:sub:P) is a subset of the set of Reflective Words (R). This means any String that is both a Word in the Language and an element of the Palindromic Pairing Language must also be a Reflective Word.

Outline: Your outline provides a good starting point, but it could benefit from some formalization and clarification:

Assume α ∈ L ∩ L:sub:P: This is a good starting point. It means α is both a Word in the Language and a String in the Palindromic Pairing Language.
Word: You correctly state that since α ∈ L, it is a Word in the Language.
Inverse Exists: You also correctly state that since α ∈ L:sub:P, it must equal its own inverse (α = inv(α)). This follows from Theorem 3.1.9.
Reflective Word: While your conclusion is correct, we need to explicitly connect the properties in steps 2 and 3 to the definition of Reflective Words (Definition 1.3.1).
Refined Proof:

Assume α ∈ L ∩ L:sub:P.

Word: Since α ∈ L, it is a Word in the Language.

Inverse Exists: Since α ∈ L:sub:P, by Theorem 3.1.9, α = inv(α).

Character-level representation: Let A = (𝔞₁ , 𝔞₂ , ..., 𝔞ₗ₍α₎) be the Character-level representation of α.

Applying inversion:  Since α = inv(α), by Definition 1.2.1 (String Inversion), we have:

(𝔞₁ , 𝔞₂ , ..., 𝔞ₗ₍α₎) = (𝔞ₗ₍α₎, ..., 𝔞₂ , 𝔞₁)

Character equality: This implies that ∀ i ∈ N:sub:l(α): 𝔞ᵢ = 𝔞ₗ₍α₎₋ᵢ₊₁.

Reflective Word: By Definition 1.3.1 (Reflective Words), since ∀ i ∈ N:sub:l(α): 𝔞ᵢ = 𝔞ₗ₍α₎₋ᵢ₊₁, it follows that α ∈ R.

Therefore, if α ∈ L ∩ L:sub:P, then α ∈ R. This implies L ∩ L:sub:P ⊆ R. ∎

Explanation of Changes:

Formalization: The proof now explicitly uses the Character-level representation of α and applies the definition of String Inversion to demonstrate the Character-level symmetry required for a Reflective Word.
Connection to Definition: The proof explicitly connects the derived properties to Definition 1.3.1 to formally establish that α is a Reflective Word.

Before moving onto the last theorem of this section, some terminology is introduced. **R** was introduced in Section () to refer to the class of Reflective Words in a Language **L**. To be more explicit in the dependence of **R** on **L**, the notation **R**:sub:`L` will be used to make explicit the Language to which the class of Reflective Words refers.

**Theorem** L:sub:`P` ⊂ R:sub:`L_σ`

This theorem can be state in natural language as follows: Given a Language L, all words in its Palindromic Pairing Language are also Reflective Words. 

In other show this theorem, it must be shown,

    1. ∀ α ∈ L: α ∈ L:sub:`P` → α ∈ R:sub:`L_σ`

Since by Definition 1.3.1, 

    2. α ∈ R:sub:`L_σ` ↔ inv(α) = α

If it can be shown,

    3. α ∈ L:sub:`P` → inv(α) = α

Then the theorem will follow tautologically from the laws of deduction. But step 3 is exactly Theorem 3.1.9. Therefore, the proof is complete. ∎

Compound Words 
^^^^^^^^^^^^^^

**Definition: Compound Words** η ∈ CW:sub:`L` ↔ [(∃ α, β ∈ L: η = αβ)  ∨  (∃ α ∈ L, ∃ γ ∈ CW:sub:`L`: η = αγ)] ∧ (η ∈ L)

This formalization can be translated into natural language as follows: A Word *η* in a Language **L** is a Compound Word if and only if,

    1. Base Case (*∃ α, β ∈ L: η = αβ*) ∧ (η ∈ L):  *η* can be formed by concatenating two words from **L**, and *η* belongs to **L**.
    2. Recursive Step [ (∃ α ∈ L, ∃ γ ∈ CW:sub:`L`: η = αγ) ∧ (η ∈ L) ]: *η* can be formed by concatenating a word from **L** with a Compound Word from **L**, and *η* belongs to **L**.


The constraint *w ∈* **L** ensures that the concatenated String *η* is not just a String, but also a valid Word within the Language **L**.

**Examples**

"teapot" is a compound word because it can be formed by concatenating "tea" and "pot", and "racecar" is itself a word in English.

"nevertheless" is a compound word formed from "never," "the," and "less."

"formrat" is not a compound word, even though it can be formed by concatenating "form" and "rat, both valid words, " because "formrat" is not a valid word in English.

**Definition: Compound Invertible Words** η ∈ CIW:sub:`L`  ↔ [ (w ∈ CW:sub:`L`)  ∧ (w ∈ I) ]

In natural language: A word w in a language L is a compound invertible word if and only if it is both a compound word and an invertible word. Using notation for set intersections, this definition can be revised to read,

    CIW:sub:`L` = CW:sub:`L` ∩ I

**Example**

"racecar" is a compound invertible word because it's both a compound word and its own inverse.

Word Concatenation
^^^^^^^^^^^^^^^^^^

Concatenation was defined in Definition 1.1.1 in terms of Characters and Strings. Every Word is a String and every String has a Character-level set representation, so the operation of concatenation will not be materially altered to accomodate Words. However, as the analysis builds toward soldifying a theory of palindromes, the result of this essential operation will be given a slightly different formal representation. This representation will not change the operation in any way, but will instead enable a more descriptive theory to emerge when the concept of a Pairing Language is introduced.

Let *α* and *β* be two words with the following Character level set representations:

    Α = { (1,  𝔞:sub:`1`), (2,  𝔞:sub:`2`), ... , (l(α),  𝔞:sub:`l(α)`) }

    Β = { (1, 𝔟:sub:`1``), (2, 𝔟:sub:`2`), ... , (l(β), 𝔟:sub:`l(β)`)}

By Definition 1.1.1, the concatenation of *α* and *β*, denoted by *αβ*, is the String *t* formed by appending the characters of *β* to the end of *α*. Formally, the set representation of *t* is given by,

    T = { (1, 𝔞:sub:`i`), (2,  𝔞:sub:`2`), ..., (l(α),  𝔞:sub:`l(α)`), (l(α) + 1, 𝔟:sub:`1`), (l(α) + 2, 𝔟:sub:`2`), ..., (l(α) + l(β), 𝔟:sub:`l(β)`)}

Note *t* is not necessarily a Word in the Language. 



TODO: there needs to be a way to establish every sentence has one word. The extraction axiom guarantees if a word is in a sentence, then it's part a language. But what about empty Sentences?

**Theorem* ∀ ζ ∈ C:sub:`L`: Λ(ζ) ≥ 1

By Definition 2.1.2, every Sentence *ζ* is an element of a Corpus **C**:sub:`L`. By Definition 2.1.1, a Corpus is a subset of the set of all Strings **S**. Therefore, every Sentence is a String.

By Definition 1.1.2, the length of a String *l(s)* is the number of non-Empty Characters in the String. 

Since a Sentence is a meaningful construct in a Language, it must contain at least one non-Empty Character. Therefore, for any Sentence ζ, l(ζ) ≥ 1.

Word Length: By Definition 2.1.6, the Word Length of a Sentence (Λ(ζ)) is defined as the cardinality of its Word-level set representation (W:sub:ζ).

Relationship between Lengths: We have previously proven (using Theorem 2.1.1) that for any Sentence ζ,  |Z| ≥ l(ζ) ≥ Λ(ζ), where |Z| is the Character Length of ζ.

Combining Inequalities: Since l(ζ) ≥ 1 (from step 2) and l(ζ) ≥ Λ(ζ) (from step 4), it follows that Λ(ζ) ≥ 1.

Therefore, every Sentence in a Corpus must have a Word Length of at least 1, meaning it contains at least one Word. ∎
